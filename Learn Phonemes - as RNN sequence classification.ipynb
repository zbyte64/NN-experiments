{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arpabet = nltk.corpus.cmudict.dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['EH1', 'S']]\n",
      "[['S', 'IY1']]\n",
      "[['S', 'IY1']]\n",
      "[['K', 'AH0', 'M', 'P', 'Y', 'UW1', 'T']]\n",
      "'comput'\n",
      "'seesea'\n"
     ]
    }
   ],
   "source": [
    "for word in ('s', 'see', 'sea', 'compute', 'comput', 'seesea'):\n",
    "    try:\n",
    "        print(arpabet[word])\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arpabet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Processing\n",
    "\n",
    "* Normalize the record sizes\n",
    "* Do not one-hot encode, leave that for the neural net\n",
    "* Do label encoding to numerics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "\n",
    "class LabelEncoder(object):\n",
    "    '''\n",
    "    A progressive label encoder\n",
    "    '''\n",
    "    def __init__(self, dim=1):\n",
    "        self.dim = dim\n",
    "        self.classes_ = dict()\n",
    "        self.lookup_ = dict()\n",
    "        self.max_sequence_size = 0\n",
    "    \n",
    "    @property\n",
    "    def n_classes(self):\n",
    "        return len(self.classes_)\n",
    "    \n",
    "    def _all_labels(self, data, update_size=False):\n",
    "        #TODO use self.dim\n",
    "        for seq in data:\n",
    "            if update_size:\n",
    "                self.max_sequence_size = max(self.max_sequence_size, len(seq))\n",
    "            for label in seq:\n",
    "                yield label\n",
    "    \n",
    "    def fit(self, data):\n",
    "        for t in map(self.tokenize_label, self._all_labels(data, update_size=True)):\n",
    "            pass\n",
    "        #self.onehot_encoder = sklearn.preprocessing.OneHotEncoder(self.n_classes)\n",
    "    \n",
    "    def refit(self, data):\n",
    "        batch_size = len(data)\n",
    "        max_size = self.max_sequence_size\n",
    "        o_encoded = np.empty((batch_size, max_size), dtype='object')\n",
    "        o_encoded.fill(self.lookup_[0])\n",
    "\n",
    "        for i, seq in enumerate(data):\n",
    "            o_encoded[i,0:len(seq)] = seq\n",
    "        return o_encoded\n",
    "    \n",
    "    def transform(self, data):\n",
    "        batch_size = len(data)\n",
    "        max_size = self.max_sequence_size\n",
    "        o_encoded = np.zeros((batch_size, max_size), dtype='int32')\n",
    "\n",
    "        for i, seq in enumerate(data):\n",
    "            for j, syl in enumerate(seq):\n",
    "                o_encoded[i,j] = self.tokenize_label(syl)\n",
    "        return o_encoded\n",
    "    \n",
    "    def inverse_transform(self, data):\n",
    "        batch_size = len(data)\n",
    "        max_size = self.max_sequence_size\n",
    "        decoded = np.zeros((batch_size, max_size), dtype='object')\n",
    "\n",
    "        for i, seq in enumerate(data):\n",
    "            for j, index in enumerate(seq):\n",
    "                decoded[i,j] = self.lookup_[index]\n",
    "        return decoded\n",
    "        \n",
    "    def onehot_label(self, label):\n",
    "        token = self.tokenize_label(label)\n",
    "        return self.onehot_encoder.fit_transform(token).toarray()\n",
    "    \n",
    "    def tokenize_label(self, label):\n",
    "        if label in self.classes_:\n",
    "            return self.classes_[label]\n",
    "        else:\n",
    "            index = len(self.classes_)\n",
    "            self.classes_[label] = index\n",
    "            self.lookup_[index] = label\n",
    "            return index\n",
    "\n",
    "\n",
    "def track_and_refit(data, null_class=''):\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit([[null_class]])\n",
    "    encoder.fit(data)\n",
    "    return encoder.transform(data), encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['（', 's', 'y', 'n', 'c', 'h', 'r', 'o', 'n', 'i', 'z', 'a', 't', 'i', 'o', 'n', '）'] ['S', 'IH2', 'NG', 'K', 'R', 'AH0', 'N', 'AH0', 'Z', 'EY1', 'SH', 'AH0', 'N']\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "WARNING:tensorflow:The default value of combiner will change from \"sum\" to \"sqrtn\" after 2016/11/01.\n",
      "133737 133737\n",
      "[ 1  2  3  4  5  6  7  8  4  9 10 11 12  9  8  4 13  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0]\n",
      "[ 1  2  3  4  5  6  7  6  8  9 10  6  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "X_, y_ = [], []\n",
    "\n",
    "for word, utterances in arpabet.items():\n",
    "    word = '\\uFF08' + word + '\\uFF09'\n",
    "    X_.extend([list(word)]*len(utterances))\n",
    "    y_.extend(utterances)\n",
    "\n",
    "    \n",
    "print(X_[0], y_[0])\n",
    "\n",
    "X, X_enc = track_and_refit(X_)\n",
    "X_classes = list(X_enc.classes_.keys())\n",
    "y, y_enc = track_and_refit(y_)\n",
    "y_classes = list(y_enc.classes_.keys())\n",
    "\n",
    "col_chars = [tf.contrib.layers.sparse_column_with_keys(column_name=\"char\"+str(i), keys=X_classes)\n",
    "            for i in range(X_enc.max_sequence_size)]\n",
    "col_seq = [tf.contrib.layers.sparse_column_with_keys(column_name=\"seq\"+str(i), keys=y_classes)\n",
    "            for i in range(y_enc.max_sequence_size)]\n",
    "\n",
    "print(len(X), len(y))\n",
    "print(X[0])\n",
    "print(y[0])\n",
    "n_classes = y_enc.n_classes\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y)#, stratify=n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpm9fm74kg\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f40e8089080>, 'tf_random_seed': None, '_environment': 'local', '_is_chief': True, '_master': '', '_task_id': 0, 'save_checkpoints_secs': 600, 'keep_checkpoint_every_n_hours': 10000, 'keep_checkpoint_max': 5, 'save_summary_steps': 100, '_num_ps_replicas': 0, 'save_checkpoints_steps': None, '_evaluation_master': '', 'tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      "}\n",
      "Model: (?, 35) -> (?, 32)\n",
      "57 71\n",
      "Features: (?, 35, 71)\n",
      "Features: (?, 32, 71)\n",
      "loss: ()\n",
      "p[0] <unknown>\n",
      "prediction: <unknown>\n",
      "[<tensorflow.python.ops.variables.Variable object at 0x7f40e3f86080>, <tensorflow.python.ops.variables.Variable object at 0x7f40e3f86048>]\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:step = 1, loss = 4.15643\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpm9fm74kg/model.ckpt.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "WARNING:tensorflow:TensorFlow's V1 checkpoint format has been deprecated.\n",
      "WARNING:tensorflow:Consider switching to the more efficient V2 format:\n",
      "WARNING:tensorflow:   `tf.train.Saver(write_version=tf.train.SaverDef.V2)`\n",
      "WARNING:tensorflow:now on by default.\n",
      "WARNING:tensorflow:*******************************************************\n",
      "INFO:tensorflow:step = 101, loss = 3.57064\n",
      "INFO:tensorflow:global_step/sec: 13.8371\n",
      "INFO:tensorflow:step = 201, loss = 3.40028\n",
      "INFO:tensorflow:global_step/sec: 14.8491\n",
      "INFO:tensorflow:step = 301, loss = 3.29933\n",
      "INFO:tensorflow:global_step/sec: 14.969\n",
      "INFO:tensorflow:step = 401, loss = 3.22027\n",
      "INFO:tensorflow:global_step/sec: 14.9456\n",
      "INFO:tensorflow:step = 501, loss = 3.12019\n",
      "INFO:tensorflow:global_step/sec: 14.8256\n",
      "INFO:tensorflow:step = 601, loss = 3.05308\n",
      "INFO:tensorflow:global_step/sec: 14.6921\n",
      "INFO:tensorflow:step = 701, loss = 2.98873\n",
      "INFO:tensorflow:global_step/sec: 14.8571\n",
      "INFO:tensorflow:step = 801, loss = 2.94334\n",
      "INFO:tensorflow:global_step/sec: 15.0904\n",
      "INFO:tensorflow:step = 901, loss = 2.86991\n",
      "INFO:tensorflow:global_step/sec: 14.9723\n",
      "INFO:tensorflow:step = 1001, loss = 2.87349\n",
      "INFO:tensorflow:global_step/sec: 15.0155\n",
      "INFO:tensorflow:step = 1101, loss = 2.83046\n",
      "INFO:tensorflow:global_step/sec: 14.984\n",
      "INFO:tensorflow:step = 1201, loss = 2.80718\n",
      "INFO:tensorflow:global_step/sec: 11.7479\n",
      "INFO:tensorflow:step = 1301, loss = 2.79647\n",
      "INFO:tensorflow:global_step/sec: 14.2815\n",
      "INFO:tensorflow:step = 1401, loss = 2.78177\n",
      "INFO:tensorflow:global_step/sec: 13.6651\n",
      "INFO:tensorflow:step = 1501, loss = 2.7658\n",
      "INFO:tensorflow:global_step/sec: 12.3982\n",
      "INFO:tensorflow:step = 1601, loss = 2.76132\n",
      "INFO:tensorflow:global_step/sec: 14.9519\n",
      "INFO:tensorflow:step = 1701, loss = 2.75518\n",
      "INFO:tensorflow:global_step/sec: 15.0264\n",
      "INFO:tensorflow:step = 1801, loss = 2.72616\n",
      "INFO:tensorflow:global_step/sec: 15.08\n",
      "INFO:tensorflow:step = 1901, loss = 2.73508\n",
      "INFO:tensorflow:global_step/sec: 14.2284\n",
      "INFO:tensorflow:step = 2001, loss = 2.74207\n",
      "INFO:tensorflow:global_step/sec: 14.4473\n",
      "INFO:tensorflow:step = 2101, loss = 2.73415\n",
      "INFO:tensorflow:global_step/sec: 12.7202\n",
      "INFO:tensorflow:step = 2201, loss = 2.73444\n",
      "INFO:tensorflow:global_step/sec: 14.8871\n",
      "INFO:tensorflow:step = 2301, loss = 2.7304\n",
      "INFO:tensorflow:global_step/sec: 14.1502\n",
      "INFO:tensorflow:step = 2401, loss = 2.71658\n",
      "INFO:tensorflow:global_step/sec: 13.4816\n",
      "INFO:tensorflow:step = 2501, loss = 2.70859\n",
      "INFO:tensorflow:global_step/sec: 11.3913\n",
      "INFO:tensorflow:step = 2601, loss = 2.71966\n",
      "INFO:tensorflow:global_step/sec: 11.9599\n",
      "INFO:tensorflow:step = 2701, loss = 2.71453\n",
      "INFO:tensorflow:global_step/sec: 13.0621\n",
      "INFO:tensorflow:step = 2801, loss = 2.70402\n",
      "INFO:tensorflow:global_step/sec: 14.6721\n",
      "INFO:tensorflow:step = 2901, loss = 2.70725\n",
      "INFO:tensorflow:global_step/sec: 14.4974\n",
      "INFO:tensorflow:step = 3001, loss = 2.71379\n",
      "INFO:tensorflow:global_step/sec: 13.3856\n",
      "INFO:tensorflow:step = 3101, loss = 2.721\n",
      "INFO:tensorflow:global_step/sec: 12.2696\n",
      "INFO:tensorflow:step = 3201, loss = 2.69491\n",
      "INFO:tensorflow:global_step/sec: 14.9648\n",
      "INFO:tensorflow:step = 3301, loss = 2.71611\n",
      "INFO:tensorflow:global_step/sec: 10.7928\n",
      "INFO:tensorflow:step = 3401, loss = 2.7079\n",
      "INFO:tensorflow:global_step/sec: 13.1284\n",
      "INFO:tensorflow:step = 3501, loss = 2.68585\n",
      "INFO:tensorflow:global_step/sec: 12.0485\n",
      "INFO:tensorflow:step = 3601, loss = 2.69046\n",
      "INFO:tensorflow:global_step/sec: 13.7887\n",
      "INFO:tensorflow:step = 3701, loss = 2.70447\n",
      "INFO:tensorflow:global_step/sec: 14.9763\n",
      "INFO:tensorflow:step = 3801, loss = 2.70496\n",
      "INFO:tensorflow:global_step/sec: 14.9368\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets, metrics, cross_validation\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib import learn\n",
    "\n",
    "#tf.reset_default_graph()\n",
    "\n",
    "\n",
    "def my_model(features, target):\n",
    "    print('Model:', features.get_shape(), '->', target.get_shape())\n",
    "    \n",
    "    feature_classes = X_enc.n_classes\n",
    "    target_classes = y_enc.n_classes\n",
    "    sequence_size = y_enc.max_sequence_size\n",
    "    print(feature_classes, target_classes)\n",
    "    target_one_hot = tf.one_hot(target, target_classes, 1, 0)\n",
    "    features = tf.to_float(tf.one_hot(features, feature_classes, 1, 0))\n",
    "\n",
    "    cell = tf.nn.rnn_cell.LSTMCell(num_units=target_classes, state_is_tuple=True)\n",
    "    \n",
    "    #lstm = tf.nn.rnn_cell.BasicLSTMCell(target_classes, state_is_tuple=True)\n",
    "    #stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * 2,\n",
    "    #    state_is_tuple=True)\n",
    "    #cell = stacked_lstm\n",
    "\n",
    "\n",
    "    outputs, states = tf.nn.dynamic_rnn(\n",
    "        cell=cell,\n",
    "        dtype=tf.float32,\n",
    "        #sequence_length=[sequence_size]*128, #should chomp based on sequence eof\n",
    "        time_major=False,\n",
    "        #sequence_length=[1, sequence_size],\n",
    "        inputs=features)\n",
    "\n",
    "    #output_fw, output_bw = outputs\n",
    "    #states_fw, states_bw = states\n",
    "\n",
    "    features = outputs\n",
    "    '''\n",
    "    result = tf.contrib.learn.run_n(\n",
    "        {\"output_fw\": output_fw, \"output_bw\": output_bw, \"states_fw\": states_fw, \"states_bw\": states_bw},\n",
    "        n=1,\n",
    "        feed_dict=None)\n",
    "    '''\n",
    "    #print('Onehot:', features.get_shape(), '->', target.get_shape())\n",
    "    \n",
    "    #conv_filter = tf.Variable(tf.zeros([5, feature_classes, target_classes]))\n",
    "    #layer = tf.nn.conv1d(features, conv_filter, stride=1, padding='SAME')\n",
    "    #features = tf.tanh(features)\n",
    "    #print('Conv1', features.get_shape())\n",
    "    \n",
    "    #features = layers.stack(features, layers.fully_connected, [target_classes, target_classes])\n",
    "    print('Features:', features.get_shape())\n",
    "    #features = tf.nn.dropout(features, .3)\n",
    "    #features = layers.fully_connected(features, target_classes, activation_fn=tf.tanh)#TODO fully connected tanh + dropout\n",
    "    features = tf.slice(features, [0,1,0], [-1, sequence_size, target_classes])\n",
    "    #features = tf.pad(features, [[0,0][0,-1],[0,0]], 'CONSTANT')\n",
    "    print('Features:', features.get_shape())\n",
    "    \n",
    "    #TODO softmax, time insensitive.\n",
    "    #bs = features.get_shape()[0]\n",
    "    #sparse_labels = tf.SparseTensor(indices=tf.argmax(target_one_hot, axis=2), values=tf.fill(bs, 1), shape=[bs, sequence_length])\n",
    "    #loss = tf.nn.ctc_loss(features, sparse_labels, sequence_length=tf.fill(bs, sequence_size), preprocess_collapse_repeated=False, ctc_merge_repeated=True, time_major=False)\n",
    "    \n",
    "    #set up sequence to sequence loss function\n",
    "    multi_feats = tf.split(1, sequence_size, features)\n",
    "    multi_targets = tf.split(1, sequence_size, target_one_hot)\n",
    "    losses = list()\n",
    "    predictions = list()\n",
    "    for seq_target, seq_feats in zip(multi_targets, multi_feats):\n",
    "        #seq_feats = tf.squeeze(seq_feats)\n",
    "        #print('S:', seq_feats.get_shape(), '->', seq_target.get_shape())\n",
    "        #seq_loss = tf.contrib.losses.softmax_cross_entropy(seq_feats, seq_target)\n",
    "        seq_pred = tf.squeeze(tf.argmax(seq_feats, 2))\n",
    "        #losses.append(seq_loss)\n",
    "        predictions.append(seq_pred)\n",
    "    #losses = tf.pack(losses)\n",
    "    #or\n",
    "    #losses = tf.nn.ctc_loss(features, target, sequence_size, time_major=False)#, preprocess_collapse_repeated=False, ctc_merge_repeated=True, time_major=True)\n",
    "    \n",
    "    #loss = tf.reduce_mean(losses)\n",
    "    logits_flat = tf.reshape(features, [-1, target_classes])\n",
    "    target_flat = tf.reshape(target, [-1])\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits_flat, labels=target_flat))\n",
    "    \n",
    "    prediction = tf.pack(predictions, axis=1)\n",
    "    \n",
    "    \n",
    "    print('loss:', loss.get_shape())\n",
    "    #print('predictions:', predictions)\n",
    "    print('p[0]', predictions[0].get_shape())\n",
    "    print('prediction:', prediction.get_shape())\n",
    "    \n",
    "    '''\n",
    "    logits = layers.fully_connected(features, target_classes) #softmax\n",
    "    #loss = tf.contrib.losses.softmax_cross_entropy(logits, target)\n",
    "    \n",
    "    #loss = tf.nn.softmax_cross_entropy_with_logits(logits, target)\n",
    "    print('logits/labels:', logits.get_shape(), target.get_shape())\n",
    "    '''\n",
    "    \n",
    "    print(tf.trainable_variables())\n",
    "    \n",
    "    #prediction, loss = (\n",
    "    #    tf.contrib.learn.models.logistic_regression_zero_init(features, target)\n",
    "    #)\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss, tf.contrib.framework.get_global_step(), optimizer='Adagrad',\n",
    "        learning_rate=0.01)\n",
    "    #return {'class': tf.argmax(prediction, 1), 'prob': prediction}\n",
    "    \n",
    "    return prediction, loss, train_op\n",
    "\n",
    "\n",
    "classifier = learn.SKCompat(learn.Estimator(model_fn=my_model))\n",
    "classifier.fit(X_train, y_train, steps=10000, batch_size=128)\n",
    "\n",
    "predictions = list(classifier.predict(X_test)) #TODO undo onhot?\n",
    "#print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"Accuracy:\", metrics.accuracy_score(y_test, predictions))\n",
    "#X_enc.inverse_transform(X_test[:5])\n",
    "#y_enc.inverse_transform(predictions[:5])\n",
    "print(X_test[0], predictions[0])\n",
    "print(X_enc.inverse_transform([X_test[0]]))\n",
    "print(y_enc.inverse_transform([predictions[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
